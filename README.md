# DHI dfsu Pipeline
This repository contains all the methods and packages necessary to construct an ETL Pipeline designed to move the raw
output of a DHI hydrodynamic model (.dfsu mesh files) to a web api that serves an interactive web dashboard that visualizes
the data.

## Table of Contents
* [Raw Data Ingestion](placeholder)

## Raw Data Ingestion
The data generated from the DHI model is represented as a 3-D mesh, meant to be plotted onto a GIS visualization tool such as
MIKE ZERO. Using the DHI python library [mikeio](placeholder) dfsu files are able to be read in as a series of nested arrays.

Data ingestion is done via the `dfsu_ingestion_engine()` object which inherits from the mikeio Dfsu() class and provides several
methods of extracting data in formats that are easily readable in a non-GIS context.

Data extracted by these methods via the input of longitude, latitude and a depth value (z-value) in some cases.  

`.get_node_data()` is a straightforward method that slices the total dataset and extracts all the category time series data based on index values generated by the mikeio method `.find_closest_element_index()`.

`.get_node_layers()` is a slightly more complicated method. Instead of extracting all the data gathered at a single point, it....
 **TODO: Re-Write .get_node_layers and update documentation after.**


```python

dfsu_ingestion_engine(filepath)

# Main Methods for extracting data:
dfsu_ingestion_engine().get_node_data(longitude, latitude, depth, data_category) # Returns data as a pandas dataframe.

dfsu_ingestion_engine().get_node_layers(longnitude, latitude, data_category) # Returns a dictionary of all data from a whole column.

```
