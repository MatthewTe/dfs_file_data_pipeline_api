# File Query API
This API is used to search for dfs file paths in the CDL HD DHI Model File Directory. This API operates within the context of a very rigid file directory structure. It was done in this way was the tradeoff of flexibility for simplicity and efficiency was well worth it.

## Table of Contents
* ### File Directory Structure
* ### `file_query_api()`

## File Directory Structure
The query api works given a path to a root directory where all DFS files are stored. This directory must conform to a very strict file structure, as this api has been designed with simplicity and efficiency as a priority over flexibility in its search. The directory structure for DFS files must follow the following structure:
```
|--|WaterForecastTT
|----|TT_HD
|------|Results
|--------|(yyyymmddhh) Date File
|----------|TimeSeries
|----------|client_name_1.dfs0
|----------|client_name_2.dfsu
|----------|client_name_1.dfs0
|----------|client_name_1.dfsu
```
The `\Results` folder contains all datetime sub-folders. The file query api operates mainly in this level of the directory.

## `file_query_api(root_dir)`
This is the main api that is used to extract dfsu files generated by the model. It is initialized with the path string of the root directory of the file structure. This would be the directory path of the `WaterForecastTT` folder.

### `get_client_data(client_name, date=None, file_type='.dfsu')`
This is the main method of the api that searches for dfsu files in the CDL directory based on a specific client. The query can be constructed without a date, in which case it returns a list of path strings for all dfs files associated with the client or a date can be specified, in which case the list returned contains only path strings of client dfsu files within the specified date range. The type of dfs file that will be written to the path list is determined by the `file_type` parameter which by default is set to `.dfsu`.

The method makes uses of conditionals and the `os.walk` method to crawl through the directory structure and selectively append file paths that meet the criteria set by the input parameters to a main list that is returned.

#### `date=None`
The date specified by the `date` parameter must be in the format used in the file directory: a string in the form `"yyyymmddhh"`.

**Note:** The query selects folders that match the specified date via the python logic:
```python
if date in dirname:
  # Perform further action
```
Due to this use of `if in` the date format can be lengthened or shortened to change the
specificity of the search:

For example setting the date parameter to `"2020"` would return all client dfsu paths for the whole year of 2020. Setting the date parameter to `"202010"` would return all client dfsu paths for October 2020 etc etc.

#### `file_type='.dfsu'`:
This parameter also uses string matching, so it is important that the string input to determine the file type is confined to the file extension otherwise unexpected files my be added to the list. It is recommended that only file extensions are used to specify file types such as: `".dfsu"` and `".dfs0"`.

### `get_client_dates(self, client_name, file_type='.dfsu)`
This method makes use of the `os.walk()` method to iterate through the entire set of Datetime folders (yyyymmddhh) and builds a list of date objects (of the same format) corresponding to the Datetime folders that contain client specific dfs files with the same extension as specified by the `file_type` parameter.

This is done by extracting the path string of a file that contains the same file extension and client name and brute force stripping the string for anything that isn't the `yyyymmddhh` sub-string within the path. This sub-string is then converted into a datetime object and written in the main list, which is then ordered in terms of recency (ascending order). It is this list that is returned

Example of how this works:

```python
# Initializing api with root directory:
test = file_query_api("C:\\Users\\teelu\\OneDrive\\Desktop\\test_data\\WaterForecastTT")

# Extracting list of date files that contain dfs0 files for the client BP_TT:
test_date_lst = test.get_client_dates('BPTT_Cipre', 'dfs0')

# -------Output-----------
test_date_lst = [ # List of unique, ordered datetime object.
    2020-06-18 12:00:00,
    2020-06-19 00:00:00,
    2020-06-19 12:00:00,
    2020-06-20 00:00:00,
    2020-06-20 12:00:00,
    2020-06-21 00:00:00,
    2020-06-21 12:00:00
      ]
```  
As stated before only date folders that contain actual dfs files have their datetime appended to the list. It is not determined by the presence of a folder, but a presence of a file of the indicated file type. It should also be noted that every date value in the list is unique. If a folder contains multiple dfs files for the same client and with the same file type it is only written once to the list.
