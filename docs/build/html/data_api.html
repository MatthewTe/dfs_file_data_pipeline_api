

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>data_api package &mdash; DFS Data Pipeline Library 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> DFS Data Pipeline Library
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">data_api package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-data_api.dfs_archive_api">data_api.dfs_archive_api module</a></li>
<li><a class="reference internal" href="#module-data_api.dfs_file_query_api">data_api.dfs_file_query_api module</a></li>
<li><a class="reference internal" href="#module-data_api.dfs_ingestion_api">data_api.dfs_ingestion_api module</a></li>
<li><a class="reference internal" href="#module-data_api.dfs_visualization_api">data_api.dfs_visualization_api module</a></li>
<li><a class="reference internal" href="#module-data_api.pipeline_api">data_api.pipeline_api module</a></li>
<li><a class="reference internal" href="#module-data_api">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">DFS Data Pipeline Library</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>data_api package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/data_api.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="data-api-package">
<h1>data_api package<a class="headerlink" href="#data-api-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-data_api.dfs_archive_api">
<span id="data-api-dfs-archive-api-module"></span><h2>data_api.dfs_archive_api module<a class="headerlink" href="#module-data_api.dfs_archive_api" title="Permalink to this headline">¶</a></h2>
<p>C:UsersteeluOneDriveDesktoptest_dataTT_HD_BPTT_Cypre_F120.dfs0</p>
<dl class="py class">
<dt id="data_api.dfs_archive_api.dfs_archive">
<em class="property">class </em><code class="sig-prename descclassname">data_api.dfs_archive_api.</code><code class="sig-name descname">dfs_archive</code><a class="headerlink" href="#data_api.dfs_archive_api.dfs_archive" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

</div>
<div class="section" id="module-data_api.dfs_file_query_api">
<span id="data-api-dfs-file-query-api-module"></span><h2>data_api.dfs_file_query_api module<a class="headerlink" href="#module-data_api.dfs_file_query_api" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="data_api.dfs_file_query_api.file_query_api">
<em class="property">class </em><code class="sig-prename descclassname">data_api.dfs_file_query_api.</code><code class="sig-name descname">file_query_api</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root_dir</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_file_query_api.file_query_api" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This object is used to contain all the variables and methods necessary to
explore the CDL file structure of the DHI HD Model’s output. It serves as an
api to access and explore said directory and, more importantly, to extract
file paths of dfs files given input parameters.</p>
<p>The object is designed mainly to be called in order to provide fil path data
for the data ingestion engine to access stored DFS files.</p>
<p>This API assumes a very strict directory structure outlined in the documentation
and will not function otherwise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>root_dir</strong> (<em>str</em>) – A filepath string representing the root or highest level DHI directory.
This is root dir is outlined in the API’s documentation.</p>
</dd>
</dl>
<dl class="py method">
<dt id="data_api.dfs_file_query_api.file_query_api.get_client_data_paths">
<code class="sig-name descname">get_client_data_paths</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">client_name</span></em>, <em class="sig-param"><span class="n">date</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">file_type</span><span class="o">=</span><span class="default_value">'.dfsu'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_file_query_api.file_query_api.get_client_data_paths" title="Permalink to this definition">¶</a></dt>
<dd><p>Method that searches the CDL directory structure for dfs files based on the
client name parameter. The search can be further specified by the optional
parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client_name</strong> (<em>str</em>) – The name of the client for which the dfs filepaths will be returned.
This string will dictate the search that is performed and as such it
is important that this string is equal to the folder name given to
the client in the CDL file directory. See Docs</p></li>
<li><p><strong>date</strong> (<em>str</em>) – A string used to specify the date from which the dfsu file paths
will be queried. The date given must correspond to the date format
of the file structure: yyyymmddhh. The level of specificity of the
date will determine the breath of the file path search. See Docs</p></li>
<li><p><strong>file_type</strong> (<em>str : default = '.dfsu'</em>) – A string that provides the method with the type of file extension
that will be retrieved. This is by default a dfsu file with the extension
‘.dfsu’ and theoretically could be any file extension but is primarily
designed to be used to extract DFS file paths such as ‘.dfsu’ and ‘.dfs0’</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>dfs_filepaths</strong> – A list of filepath strings that were extracted based on the search
parameters specified by the method.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_file_query_api.file_query_api.get_client_dates">
<code class="sig-name descname">get_client_dates</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">client_name</span></em>, <em class="sig-param"><span class="n">file_type</span><span class="o">=</span><span class="default_value">'.dfsu'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_file_query_api.file_query_api.get_client_dates" title="Permalink to this definition">¶</a></dt>
<dd><p>This method uses the os.walk method to iterate through the list of all
yyyymmddhh file directories and builds a list of datetimes in which the
client_name sub-folder contains dfsu files. The end goal of this method
is to provide a means of creating an ordered timeseries of dfsu files.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client_name</strong> (<em>str</em>) – A string representing the name of the client of which the files are
being searched. It is critical that the client_name string be equal to
the flie name for the client sub-folder. See Docs for more info.</p></li>
<li><p><strong>file_type</strong> (<em>str : default = '.dfsu'</em>) – A string that provides the method with the type of file extension
that the algorithm will use to search for date values. This is by
default a dfsu file with the extension ‘.dfsu’ and theoretically could
be any file extension but is primarily designed to be used to extract
DFS file paths such as ‘.dfsu’ and ‘.dfs0’</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>date_lst</strong> – A list containing datetime strings of each date folder that contains
client specific files.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
<p>:raises Exception : Exception: An error that occurs if a client name string is not correctly defined.
    Halts the building of the date_lst as brute-force string slicing is no
    longer possible.</p>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_file_query_api.file_query_api.get_dfs0_list">
<code class="sig-name descname">get_dfs0_list</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">client_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_file_query_api.file_query_api.get_dfs0_list" title="Permalink to this definition">¶</a></dt>
<dd><p>This method iterates through the list of dfs0 file paths generated from the
self.get_client_data_paths(), initalizes these paths as dfs0_ingestion objects
and builds and returns a key-value dict of {‘timeseries’: dfs0 dataframe}.
The dfs0 dataframe is the self.main_df dataframe extracted from the ingestion
object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>client_name</strong> (<em>str</em>) – The name of the client for which the dfs filepaths will be generated.
Via the self.get_client_data_paths(client_name).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>path_dict</strong> – A key value dictionary that contains all the key-value pairs of format
{datetime : dataframe} from the client data path list.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_file_query_api.file_query_api.get_seven_day_forcast_files">
<code class="sig-name descname">get_seven_day_forcast_files</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">client_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_file_query_api.file_query_api.get_seven_day_forcast_files" title="Permalink to this definition">¶</a></dt>
<dd><p>This method implements the Seven Day Forecasting File search algorithm to
buid a dictionary of the most recent 7-day forcasting dfs0 data for a
client in the CDL file directory. See Documentation for full description.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>client_name</strong> (<em>str</em>) – This is the client name string that will be used to search the file
directory for client_specific dfs0 files.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>forecast_dict</strong> – A dictionary containing all the forecasting data for the client within the
7-day period. It is stored as key-value pairs of
{‘TimeSeries value’: ‘dfs0 File Path’}.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-data_api.dfs_ingestion_api">
<span id="data-api-dfs-ingestion-api-module"></span><h2>data_api.dfs_ingestion_api module<a class="headerlink" href="#module-data_api.dfs_ingestion_api" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="data_api.dfs_ingestion_api.dfs0_ingestion_engine">
<em class="property">class </em><code class="sig-prename descclassname">data_api.dfs_ingestion_api.</code><code class="sig-name descname">dfs0_ingestion_engine</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">filepath</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfs0_ingestion_engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mikeio.dfs0.Dfs0</span></code></p>
<p>This is the object that ingests a dfs0 file based on a file path and provides
a series of APIs that allows data to be queried and retrieved. The base for all
of the method APIs comes from the Dfs0 object inherited from the mikeio software
library.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filepath</strong> (<em>str</em>) – A string representing the path to the dfs0 file that is going to be parsed</p>
</dd>
</dl>
<dl class="py method">
<dt id="data_api.dfs_ingestion_api.dfs0_ingestion_engine.concat_df">
<code class="sig-name descname">concat_df</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataframe</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfs0_ingestion_engine.concat_df" title="Permalink to this definition">¶</a></dt>
<dd><p>Method compares the format of the input dataframe to the dataframe generated
via the dfs0_ingestion_engine. If the formats match, the input dataframe
is appened to the main instance dataframe. The method does not return a
value, it modifies the instance dataframe: self.main_df.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dataframe</strong> (<em>pandas dataframe</em>) – This is the dataframe that will be appended onto the main dataframe.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_ingestion_api.dfs0_ingestion_engine.concat_df_list">
<code class="sig-name descname">concat_df_list</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfs0_ingestion_engine.concat_df_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Method is simply an iterative implementation of the concat_df() method.
It attempts to append every dataframe passed into the method to the instance
dataframe self.main_df.</p>
<p>Like concat_df() this method does not return a parameter. It modifies an
instace dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>*args</strong> (<em>arguments</em>) – These arguments are intended to be dataframes as each of these inserted
arguments will attempt to appended each of the dataframes to the main
self.main_df</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="data_api.dfs_ingestion_api.dfsu_ingestion_engine">
<em class="property">class </em><code class="sig-prename descclassname">data_api.dfs_ingestion_api.</code><code class="sig-name descname">dfsu_ingestion_engine</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">filepath</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfsu_ingestion_engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mikeio.dfsu.Dfsu</span></code></p>
<p>The ingestion engine ingests a dfsu file path and provides a series of APIs
directly based off of the mikeio DHI library to query and extract Dfsu data
in a simplified form</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filepath</strong> (<em>str</em>) – The filepath of the .dfsu file.</p>
</dd>
</dl>
<dl class="py method">
<dt id="data_api.dfs_ingestion_api.dfsu_ingestion_engine.extract_data">
<code class="sig-name descname">extract_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data_category</span></em>, <em class="sig-param"><span class="n">element_index</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfsu_ingestion_engine.extract_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Method that extracts the data from the main .dfsu dataset by slicing said
dataset by both category and by slice determined index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_category</strong> (<em>str</em>) – The data category (type) that will be used slice the dataframe based on
different data types</p></li>
<li><p><strong>index</strong> (<em>int</em>) – An integer representing the index location of the data in the dataset.
This will be used to perform another slice on the dataset.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>slice_df</strong> – A dataframe that is generated and formatted based on the dataset
sliced via data_category and index.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas dataframe</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_ingestion_api.dfsu_ingestion_engine.get_node_data">
<code class="sig-name descname">get_node_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">long</span></em>, <em class="sig-param"><span class="n">lat</span></em>, <em class="sig-param"><span class="n">depth</span></em>, <em class="sig-param"><span class="n">cat_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfsu_ingestion_engine.get_node_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Method takes locational data and a category name and produces a
dataframe containing all data for the category at a particular node
given the locational data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>long</strong> (<em>float</em>) – The longnitude value of the location point</p></li>
<li><p><strong>lat</strong> (<em>float</em>) – The latitude value of the location point</p></li>
<li><p><strong>depth</strong> (<em>float : Default = None</em>) – The depth value of the location point</p></li>
<li><p><strong>cat_name</strong> (<em>str</em>) – The string that is used to slice the main array to extract
only the data pertaining to that category</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self.extract_data()</strong> – The method calls and returns the method .extract_data() which slices
the main dataset, builds a dataframe based on said sliced data and
returns a dataframe.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas dataframe</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_ingestion_api.dfsu_ingestion_engine.get_node_layers">
<code class="sig-name descname">get_node_layers</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">long</span></em>, <em class="sig-param"><span class="n">lat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfsu_ingestion_engine.get_node_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Method extracts all the index values associated with a single long/lat point.
Unlike .get_node_data this method extracts the data for said category at
all elevation levels (at all z-values) associated with the long/lat point.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>long</strong> (<em>float</em>) – The longnitude value for the node that is being extracted</p></li>
<li><p><strong>lat</strong> (<em>float</em>) – The latitude value for the node that is being extracted</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>layers_dict</strong> – A dictionary containing key-value pairs of z-value determined layers
and the index values indicating the location of the data containing
the relevant data at each layer. Each element in the dict can be
represented as a dataframe using the self.extract_data() method.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_ingestion_api.dfsu_ingestion_engine.get_node_polar_coords">
<code class="sig-name descname">get_node_polar_coords</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">long</span></em>, <em class="sig-param"><span class="n">lat</span></em>, <em class="sig-param"><span class="n">depth</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_ingestion_api.dfsu_ingestion_engine.get_node_polar_coords" title="Permalink to this definition">¶</a></dt>
<dd><p>Method calls existing data slicing methods to extract data pertaining to
Speed and Horizontal Direction of currents at a single node (long,lat,depth)</p>
<p>The method then transforms the radial directional data into degrees that
can be plotted onto a polar coordinate system.</p>
<ul class="simple">
<li><p>Assumes polar coordinate format (r, theta).</p></li>
<li><dl class="simple">
<dt>Collects data based on Dataset[‘Current speed’] &amp;</dt><dd><p>Dataset[‘Current direction’]</p>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>long</strong> (<em>float</em>) – The longnitude value of the location point</p></li>
<li><p><strong>lat</strong> (<em>float</em>) – The latitude value of the location point</p></li>
<li><p><strong>depth</strong> (<em>float</em>) – The depth value of the location point</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>polar_df</strong> – A two column dataframe containing all the time series data for
Current speeds and Current direction that can be expressed by a polar
coordinate system as (r=Currnet speeds, theta=Current direction)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas dataframe</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-data_api.dfs_visualization_api">
<span id="data-api-dfs-visualization-api-module"></span><h2>data_api.dfs_visualization_api module<a class="headerlink" href="#module-data_api.dfs_visualization_api" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="data_api.dfs_visualization_api.dashboard">
<em class="property">class </em><code class="sig-prename descclassname">data_api.dfs_visualization_api.</code><code class="sig-name descname">dashboard</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">filepath</span></em>, <em class="sig-param"><span class="n">gis_filepath</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.dashboard" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#data_api.dfs_ingestion_api.dfsu_ingestion_engine" title="data_api.dfs_ingestion_api.dfsu_ingestion_engine"><code class="xref py py-class docutils literal notranslate"><span class="pre">data_api.dfs_ingestion_api.dfsu_ingestion_engine</span></code></a></p>
<p>The dashboard object is used to ingest data generated by the dfsu_ingestion_engine
and provide an API that allows dashboards displaying the data to be generated and
displayed using the plotly library.</p>
<p>The object is initalized via a filepath and uses its various methods
to return plotly figure objects that can be compiled into a dashboard.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filepath</strong> (<em>str</em>) – The filepath of the .dfsu file used to initalize the dfsu_ingestion_engine</p></li>
<li><p><strong>gis_filepath</strong> (<em>str</em>) – This is the filepath of the GeoJSON file that will be used to initalize the
gis_model() object used for plotting maps and spatial visualization.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="data_api.dfs_visualization_api.dashboard.create_polar_plot">
<code class="sig-name descname">create_polar_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">long</span></em>, <em class="sig-param"><span class="n">lat</span></em>, <em class="sig-param"><span class="n">depth</span></em>, <em class="sig-param"><span class="n">r_column</span></em>, <em class="sig-param"><span class="n">theta_column</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.dashboard.create_polar_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Method plots and returns a plotly graph object that contains a polar/radial
plot based on the input coordinates and the graph format pulled from a
formatting dictionary</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>long</strong> (<em>float</em>) – The longnitude value of the location point</p></li>
<li><p><strong>lat</strong> (<em>float</em>) – The latitude value of the location point</p></li>
<li><p><strong>depth</strong> (<em>float</em>) – The depth value of the location point</p></li>
<li><p><strong>r_column</strong> (<em>str</em>) – A string indicating the data category that will be extracted to form
the r values in the (r, theta) polar coordinate system via the data
extraction api.</p></li>
<li><p><strong>theta_column</strong> (<em>str</em>) – A string indicating the data category that will be extracted to form
the theta values in the (r, theta) polar coordinate system via the data
extraction api. This value MUST be either radians or degrees.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>barpolar_plot</strong> – A plotly graphing object that can be inserted into a plotly figure.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>plotly.graph_objects</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_visualization_api.dashboard.create_timeseries">
<code class="sig-name descname">create_timeseries</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">long</span></em>, <em class="sig-param"><span class="n">lat</span></em>, <em class="sig-param"><span class="n">depth</span></em>, <em class="sig-param"><span class="n">plot_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.dashboard.create_timeseries" title="Permalink to this definition">¶</a></dt>
<dd><p>Method plots and returns a plotly graph objects of timeseries data. The
data is extracted from the dfsu_ingestion_engine and the format of the
timeseries is set by the timeseries_format dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>long</strong> (<em>float</em>) – The longnitude value of the location point</p></li>
<li><p><strong>lat</strong> (<em>float</em>) – The latitude value of the location point</p></li>
<li><p><strong>depth</strong> (<em>float</em>) – The depth value of the location point</p></li>
<li><p><strong>plot_name</strong> (<em>str</em>) – This is the category string that will be used to retrieve the dfsu data
and to determine the format of the timeseries.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>timeseries_plot</strong> – The plotly graph object that can be plotted either as a standalone or
onto a subplot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>plotly.graph_objects</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_visualization_api.dashboard.plot_node_data">
<code class="sig-name descname">plot_node_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">long</span></em>, <em class="sig-param"><span class="n">lat</span></em>, <em class="sig-param"><span class="n">depth</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.dashboard.plot_node_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Method returns a plotly figure object containing all the relevant graphs
for a dfsu file that contains the following data categories:</p>
<blockquote>
<div><ul class="simple">
<li><p>Current speed (meter per sec)</p></li>
<li><p>Density (kg per meter pow 3)</p></li>
<li><p>Temperature (degree Celsius)</p></li>
<li><p>Current direction (Horizontal) (radian)</p></li>
<li><p>Salinity (PSU)</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>long</strong> (<em>float</em>) – The longnitude value of the location point</p></li>
<li><p><strong>lat</strong> (<em>float</em>) – The latitude value of the location point</p></li>
<li><p><strong>depth</strong> (<em>float</em>) – The depth value of the location point</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>subplot_figure</strong> – This is the figure object that in this case contains subplots
with all the relevant graphs plotted. It is intended to be placed
passed into a Dash applicaiton or a Django view.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>plotly figure object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_visualization_api.dashboard.plot_water_column_table">
<code class="sig-name descname">plot_water_column_table</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">long</span></em>, <em class="sig-param"><span class="n">lat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.dashboard.plot_water_column_table" title="Permalink to this definition">¶</a></dt>
<dd><p>This method generates a plotly figure that displays a summary table of
information on each water column for a specific long, lat point.</p>
<p>The table contains the depth of each depth level, the corresponding
average data values for each depth level on:</p>
<ul class="simple">
<li><p>Current Speed</p></li>
<li><p>Water Salinity</p></li>
<li><p>Water Temperature</p></li>
<li><p>Water Density</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>long</strong> (<em>float</em>) – The longnitude value of the location point</p></li>
<li><p><strong>lat</strong> (<em>float</em>) – The latitude value of the location point</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>table_figure</strong> – This is the plotly graph object that displays a table of summary data
for each water depth layer at a specific long and lat point.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>plotly graph object</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="data_api.dfs_visualization_api.gis_model">
<em class="property">class </em><code class="sig-prename descclassname">data_api.dfs_visualization_api.</code><code class="sig-name descname">gis_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">center_loc</span></em>, <em class="sig-param"><span class="n">client_model</span></em>, <em class="sig-param"><span class="n">access_token</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.gis_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This object is used to store information and build data structures about
the GIS model for a specific client Dashboard. The main data structures
generated by input parameters are used to create an interactive Matchbox
map.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>center_loc</strong> (<em>tuple</em>) – A tuple of (lat,long) data that represents the center of the map area.
This tuple would be used to center the Scattermapbox satellite map.</p></li>
<li><p><strong>client_model</strong> (<em>str</em>) – The string representing the name of the client model that the object is
plotting. It will be used to query data from the file directory via
the data API.</p></li>
<li><p><strong>access_token</strong> (<em>str</em>) – The access token for the Mapbox API.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="data_api.dfs_visualization_api.gis_model.build_coord_lst">
<code class="sig-name descname">build_coord_lst</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.gis_model.build_coord_lst" title="Permalink to this definition">¶</a></dt>
<dd><p>Internal method that queries the file search api and builds a list of all
the lat and long points that will be displayed on this instance of the
GIS model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coord_dict</strong> – A python dictionary that contains all of the latitude and longnitude
data to be plotted onto the Scattermapbox plot. Dict follows the structure:
{‘lat’: [list of lat values], ‘long’: [list of long values]}</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="data_api.dfs_visualization_api.gis_model.build_map_fig">
<code class="sig-name descname">build_map_fig</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#data_api.dfs_visualization_api.gis_model.build_map_fig" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-data_api.pipeline_api">
<span id="data-api-pipeline-api-module"></span><h2>data_api.pipeline_api module<a class="headerlink" href="#module-data_api.pipeline_api" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="data_api.pipeline_api.dfs0_pipeline">
<em class="property">class </em><code class="sig-prename descclassname">data_api.pipeline_api.</code><code class="sig-name descname">dfs0_pipeline</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">client_name</span></em>, <em class="sig-param"><span class="n">root_dir</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.pipeline_api.dfs0_pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This is the main object that makes use of all other dfs0 apis. It contains
all the processes that are necessary for maintaining a data stream of dfs0
files generated for a specific client.</p>
<p>This is the main object that contains all the methods that transfer dfs0 data
between processes in the data pipeline as well as maintain a master dataframe
of all client data in a single TimeSeries stored in a sqlite database and
extracted as a dataframe.</p>
<p>The object is initalized with all the parameters necessary to initalize/interact
with all of the dfs api methods within the data_api package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client_name</strong> (<em>str</em>) – A string that represents the client name / client project name of the pipeline
object. This is the client name that will be used by various methods to extract
dfs0 file paths via the file_query_api.</p></li>
<li><p><strong>root_dir</strong> (<em>str</em>) – A path string that represents the path to the root file directory where the
HD Model output files are stored / written to. This is the root_dir string
that will be used to initalize the file_query_api method.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="data_api.pipeline_api.dfs0_pipeline.build_seven_day_forecast_data">
<code class="sig-name descname">build_seven_day_forecast_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">date</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.pipeline_api.dfs0_pipeline.build_seven_day_forecast_data" title="Permalink to this definition">¶</a></dt>
<dd><p>This method makes uses of the get_seven_day_forcast_files() method in the
file query api to build a pandas dataframe containing the TimeSeries data
for the seven day forecast.</p>
<p>The method iterates through the dictionary of dfs0 paths, generates a list
of those paths within seven days using the date string keys of the dict.
The method then initalizes all the dfs0 paths using the dfs0 ingestion
engine and concatinates all the dfs0 dataframes into a single dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>date</strong> (<em>tuple</em>) – A tuple that by default is None. If the tuple is input, it must be in
the form (year, month, day) as integers. It is used to create the
‘current_date’ varable that is used as the starting point of the
seven day file search-concatenation algo. This parameter is mainly
used for back-testing and development.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>forecast_df</strong> – The dataframe containing all the forecasting data. This is generated
as the result of dataframe list concatenation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas dataframe</p>
</dd>
</dl>
<p>:raises ValueError : ValueError: The error that is raised at the end of the method when no dataframes
    are found to be concatinated.</p>
</dd></dl>

<dl class="py method">
<dt id="data_api.pipeline_api.dfs0_pipeline.write_csv">
<code class="sig-name descname">write_csv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">df</span></em>, <em class="sig-param"><span class="n">file_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#data_api.pipeline_api.dfs0_pipeline.write_csv" title="Permalink to this definition">¶</a></dt>
<dd><p>Method that converts a formatted pandas dataframe to a .csv file at a
specified file path in the root directory based on input file name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pandas dataframe</em>) – The (most likely) concatinated pandas dataframe that the method will
convert to a .csv file.</p></li>
<li><p><strong>pathname</strong> (<em>str</em>) – A string representing the name of the .csv file to be written to the
file directory. The file_name string is used to build the path string
that dictates where the file is written.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-data_api">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-data_api" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Matthew Teelucksingh

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>